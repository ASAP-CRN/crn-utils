{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_schema import v2_to_v3, v1_to_v2, reorder_table_to_CDE\n",
    "from util import read_CDE, read_meta_table, NULL\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. get the schemas\n",
    "\n",
    "\n",
    "## 2. locate the metadata path\n",
    "\n",
    "\n",
    "## 3. update\n",
    "\n",
    "\n",
    "\n",
    "## 4.  generate version reports... i.e. changes between versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_version: ASAP_CDE_v1\n",
      "https://docs.google.com/spreadsheets/d/1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc/gviz/tq?tqx=out:csv&sheet=v1\n",
      "/Users/ergonyc/Projects/ASAP/crn-utils/resource/CDE/ASAP_CDE_v1.csv\n",
      "read local file\n"
     ]
    }
   ],
   "source": [
    "schema_version = \"v1\"\n",
    "schema_path = Path.home() / \"Projects/ASAP/crn-utils/resource/CDE\"\n",
    "CDEv1 = read_CDE(schema_version, local_path=schema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_version: ASAP_CDE_v2.1\n",
      "https://docs.google.com/spreadsheets/d/1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc/gviz/tq?tqx=out:csv&sheet=v2.1\n",
      "/Users/ergonyc/Projects/ASAP/crn-utils/resource/CDE/ASAP_CDE_v2.1.csv\n",
      "read local file\n",
      "metadata_version: ASAP_CDE_v3.0\n",
      "https://docs.google.com/spreadsheets/d/1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc/gviz/tq?tqx=out:csv&sheet=v3.0\n",
      "/Users/ergonyc/Projects/ASAP/crn-utils/resource/CDE/ASAP_CDE_v3.0.csv\n",
      "read local file\n"
     ]
    }
   ],
   "source": [
    "schema_version = \"v2.1\"\n",
    "CDEv2 = read_CDE(schema_version, local_path=schema_path)\n",
    "schema_version = \"v3.0\"\n",
    "CDEv3 = read_CDE(schema_version, local_path=schema_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SANITY CHECK: verify reading from google doc works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_version: ASAP_CDE_v1\n",
      "https://docs.google.com/spreadsheets/d/1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc/gviz/tq?tqx=out:csv&sheet=v1\n",
      "read url\n",
      "metadata_version: ASAP_CDE_v2.1\n",
      "https://docs.google.com/spreadsheets/d/1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc/gviz/tq?tqx=out:csv&sheet=v2.1\n",
      "read url\n",
      "metadata_version: ASAP_CDE_v3.0\n",
      "https://docs.google.com/spreadsheets/d/1c0z5KvRELdT2AtQAH2Dus8kwAyyLrR0CROhKOjpU4Vc/gviz/tq?tqx=out:csv&sheet=v3.0\n",
      "read url\n"
     ]
    }
   ],
   "source": [
    "CDEv1_ = read_CDE(\"v1\")\n",
    "CDEv2_ = read_CDE(\"v2.1\")\n",
    "CDEv3_ = read_CDE(\"v3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_CDEs(df1, df2):\n",
    "    \"\"\"\n",
    "    Compares two pandas dataframes and returns if they are identical or not.\n",
    "    If they are not identical, it returns the differences between the two dataframes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort both dataframes by 'Table' and 'Field' before comparison\n",
    "    df1 = df1.sort_values(by=['Table', 'Field']).reset_index(drop=True)\n",
    "    df2 = df2.sort_values(by=['Table', 'Field']).reset_index(drop=True)\n",
    "    \n",
    "    if df1.equals(df2):\n",
    "        return \"The dataframes are identical.\"\n",
    "    \n",
    "    differences = []\n",
    "    \n",
    "    # Check for differences in values\n",
    "    df1_diff = df1 != df2\n",
    "    diff_rows, diff_cols = df1_diff.stack()[df1_diff.stack()].index.to_list(), df1_diff.columns[df1_diff.any()]\n",
    "    \n",
    "    for row, col in diff_rows:\n",
    "        differences.append(\n",
    "            f\"Difference at row {row}, column '{col}': \"\n",
    "            f\"df1 value = {df1.loc[row, col]}, df2 value = {df2.loc[row, col]}\"\n",
    "        )\n",
    "    \n",
    "    return differences if differences else \"No differences found in data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataframes are identical.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_CDEs(CDEv1, CDEv1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataframes are identical.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_CDEs(CDEv2, CDEv2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Difference at row 0, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 2, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 5, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 8, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 10, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 11, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 13, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 14, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 16, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 21, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 22, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 25, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 33, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 34, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 35, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 38, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 39, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 40, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 41, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 42, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 43, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 44, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 58, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 60, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 61, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 62, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 63, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 64, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 65, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 66, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 67, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 69, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 70, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 71, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 73, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 74, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 75, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 77, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 78, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 79, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 80, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 81, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 82, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 83, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 84, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 85, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 90, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 91, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 92, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 93, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 94, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 95, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 96, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 97, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 98, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 99, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 100, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 102, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 103, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 104, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 105, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 106, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 107, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 111, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 112, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 113, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 114, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 115, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 117, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 118, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 119, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 120, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 121, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 122, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 123, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 124, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 125, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 127, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 128, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 129, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 130, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 131, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 132, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 133, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 134, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 135, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 136, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 137, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 138, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 139, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 140, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 141, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 142, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 143, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 144, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 145, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 146, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 147, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 148, column 'Description': df1 value = Sample Type. :   \\r\\nDescription of samples.  e.g.: late-stage PD and control postmortem brains, df2 value = Sample Type. :   \\nDescription of samples.  e.g.: late-stage PD and control postmortem brains\",\n",
       " \"Difference at row 148, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 149, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 150, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 152, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 155, column 'Validation': df1 value = nan, df2 value = nan\",\n",
       " \"Difference at row 156, column 'Validation': df1 value = nan, df2 value = nan\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_CDEs(CDEv3, CDEv3_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Required</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Required</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP Team Name:   Name of the ASAP CRN Team. i...</td>\n",
       "      <td>Enum</td>\n",
       "      <td>Required</td>\n",
       "      <td>[\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\", \"TEAM-...</td>\n",
       "      <td>STUDY</td>\n",
       "      <td>ASAP_team_name</td>\n",
       "      <td>ASAP Team Name:   Name of the ASAP CRN Team. i...</td>\n",
       "      <td>Enum</td>\n",
       "      <td>Required</td>\n",
       "      <td>[\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\", \"TEAM-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>Lab Name. :   Lab name that is submitting data...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDY</td>\n",
       "      <td>ASAP_lab_name</td>\n",
       "      <td>Lab Name. :   Lab name that is submitting data...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_name</td>\n",
       "      <td>Project Name:   A Title of the overall project...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_name</td>\n",
       "      <td>Project Name:   A Title of the overall project...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>team_dataset_id</td>\n",
       "      <td>The \"project_name\" is often too verbose for pr...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDY</td>\n",
       "      <td>team_dataset_id</td>\n",
       "      <td>The \"project_name\" is often too verbose for pr...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Dataset Name:   A unique name is required for ...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STUDY</td>\n",
       "      <td>project_dataset</td>\n",
       "      <td>Dataset Name:   A unique name is required for ...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>CONDITION</td>\n",
       "      <td>protocol_id</td>\n",
       "      <td>ID for referencing the protocols for intervent...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONDITION</td>\n",
       "      <td>protocol_id</td>\n",
       "      <td>ID for referencing the protocols for intervent...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>CONDITION</td>\n",
       "      <td>intervention_aux_table</td>\n",
       "      <td>Table which defines all experimental condition...</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONDITION</td>\n",
       "      <td>intervention_aux_table</td>\n",
       "      <td>Table which defines all experimental condition...</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>MOUSE</td>\n",
       "      <td>subject_id</td>\n",
       "      <td>The Subject ID.  This will be a unique ID for ...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>subject_id</td>\n",
       "      <td>The Subject ID.  This will be a unique ID for ...</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>MOUSE</td>\n",
       "      <td>strain</td>\n",
       "      <td>Strain:   Mouse strain details</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>strain</td>\n",
       "      <td>Strain:   Mouse strain details</td>\n",
       "      <td>String</td>\n",
       "      <td>Required</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>MOUSE</td>\n",
       "      <td>aux_table</td>\n",
       "      <td>Table which defines additional mouse \"subject\"...</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MOUSE</td>\n",
       "      <td>aux_table</td>\n",
       "      <td>Table which defines additional mouse \"subject\"...</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Table                   Field  \\\n",
       "0        STUDY          ASAP_team_name   \n",
       "1        STUDY           ASAP_lab_name   \n",
       "2        STUDY            project_name   \n",
       "3        STUDY         team_dataset_id   \n",
       "4        STUDY         project_dataset   \n",
       "..         ...                     ...   \n",
       "152  CONDITION             protocol_id   \n",
       "153  CONDITION  intervention_aux_table   \n",
       "154      MOUSE              subject_id   \n",
       "155      MOUSE                  strain   \n",
       "156      MOUSE               aux_table   \n",
       "\n",
       "                                           Description DataType  Required  \\\n",
       "0    ASAP Team Name:   Name of the ASAP CRN Team. i...     Enum  Required   \n",
       "1    Lab Name. :   Lab name that is submitting data...   String  Required   \n",
       "2    Project Name:   A Title of the overall project...   String  Required   \n",
       "3    The \"project_name\" is often too verbose for pr...   String  Required   \n",
       "4    Dataset Name:   A unique name is required for ...   String  Required   \n",
       "..                                                 ...      ...       ...   \n",
       "152  ID for referencing the protocols for intervent...   String  Required   \n",
       "153  Table which defines all experimental condition...   String  Optional   \n",
       "154  The Subject ID.  This will be a unique ID for ...   String  Required   \n",
       "155                     Strain:   Mouse strain details   String  Required   \n",
       "156  Table which defines additional mouse \"subject\"...   String  Optional   \n",
       "\n",
       "                                            Validation      Table  \\\n",
       "0    [\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\", \"TEAM-...      STUDY   \n",
       "1                                                  NaN      STUDY   \n",
       "2                                                  NaN      STUDY   \n",
       "3                                                  NaN      STUDY   \n",
       "4                                                  NaN      STUDY   \n",
       "..                                                 ...        ...   \n",
       "152                                                NaN  CONDITION   \n",
       "153                                                NaN  CONDITION   \n",
       "154                                                NaN      MOUSE   \n",
       "155                                                NaN      MOUSE   \n",
       "156                                                NaN      MOUSE   \n",
       "\n",
       "                      Field  \\\n",
       "0            ASAP_team_name   \n",
       "1             ASAP_lab_name   \n",
       "2              project_name   \n",
       "3           team_dataset_id   \n",
       "4           project_dataset   \n",
       "..                      ...   \n",
       "152             protocol_id   \n",
       "153  intervention_aux_table   \n",
       "154              subject_id   \n",
       "155                  strain   \n",
       "156               aux_table   \n",
       "\n",
       "                                           Description DataType  Required  \\\n",
       "0    ASAP Team Name:   Name of the ASAP CRN Team. i...     Enum  Required   \n",
       "1    Lab Name. :   Lab name that is submitting data...   String  Required   \n",
       "2    Project Name:   A Title of the overall project...   String  Required   \n",
       "3    The \"project_name\" is often too verbose for pr...   String  Required   \n",
       "4    Dataset Name:   A unique name is required for ...   String  Required   \n",
       "..                                                 ...      ...       ...   \n",
       "152  ID for referencing the protocols for intervent...   String  Required   \n",
       "153  Table which defines all experimental condition...   String  Optional   \n",
       "154  The Subject ID.  This will be a unique ID for ...   String  Required   \n",
       "155                     Strain:   Mouse strain details   String  Required   \n",
       "156  Table which defines additional mouse \"subject\"...   String  Optional   \n",
       "\n",
       "                                            Validation  \n",
       "0    [\"TEAM-LEE\",\"TEAM-HAFLER\",\"TEAM-HARDY\", \"TEAM-...  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "152                                                NaN  \n",
       "153                                                NaN  \n",
       "154                                                NaN  \n",
       "155                                                NaN  \n",
       "156                                                NaN  \n",
       "\n",
       "[157 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([CDEv3, CDEv3_],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_schema import filter_table_columns, reorder_table_to_CDE\n",
    "\n",
    "def v1_to_v2(tables_path: str | Path, out_dir: str|None, CDEv1: pd.DataFrame, CDEv2: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Load the tables from the tables_path, and update them to the CDEv2 schema.\n",
    "    Export the new tables to a datestamped out_dir.\n",
    "    \"\"\"\n",
    "    # Get the current date and time\n",
    "    current_date = datetime.datetime.now()\n",
    "        \n",
    "    STUDYv1 = read_meta_table(f\"{tables_path}/STUDY.csv\")\n",
    "    PROTOCOLv1 = read_meta_table(f\"{tables_path}/PROTOCOL.csv\")\n",
    "    SUBJECTv1 = read_meta_table(f\"{tables_path}/SUBJECT.csv\")\n",
    "    CLINPATHv1 = read_meta_table(f\"{tables_path}/CLINPATH.csv\")\n",
    "    SAMPLEv1 = read_meta_table(f\"{tables_path}/SAMPLE.csv\")\n",
    "\n",
    "    # STUDY\n",
    "    STUDYv2 = STUDYv1.copy() # don't really need to copy here\n",
    "    # assert len(SAMPLEv1['preprocessing_references'].unique()) == 1\n",
    "    STUDYv2['preprocessing_references'] = SAMPLEv1['preprocessing_references'][0]\n",
    "    STUDYv2['team_dataset_id'] = STUDYv2['project_dataset'].str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "\n",
    "    # PROTOCOL\n",
    "    PROTOCOLv2 = PROTOCOLv1.copy()  \n",
    "\n",
    "    SAMP_CLIN = SAMPLEv1.merge(CLINPATHv1, on=\"sample_id\", how=\"left\")\n",
    "    SAMP_CLIN['source_sample_id'] = SAMP_CLIN['source_sample_id_x']\n",
    "    SAMP_CLIN = SAMP_CLIN.drop(columns=['source_sample_id_x','source_sample_id_y'])\n",
    "\n",
    "    SUBJ_SAMP_CLIN = SUBJECTv1.merge(SAMP_CLIN, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "    SUBJECTv2 = filter_table_columns(SUBJ_SAMP_CLIN, CDEv2, \"SUBJECT\")\n",
    "    CLINPATHv2 = filter_table_columns(SUBJ_SAMP_CLIN, CDEv2, \"CLINPATH\")\n",
    "    SAMPLEv2 = filter_table_columns(SUBJ_SAMP_CLIN, CDEv2, \"SAMPLE\")\n",
    "\n",
    "    DATAv2 = filter_table_columns(SAMPLEv1, CDEv2, \"DATA\")\n",
    "\n",
    "    if out_dir is not None:\n",
    "        # Prepare output directory\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        export_root = Path(tables_path) / f\"{out_dir}_{date_str}\"\n",
    "        export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Export the tables\n",
    "        STUDYv2.to_csv(export_root / \"STUDY.csv\", index=False)\n",
    "        PROTOCOLv2.to_csv(export_root / \"PROTOCOL.csv\", index=False)\n",
    "        SAMPLEv2.to_csv(export_root / \"SAMPLE.csv\", index=False)\n",
    "        SUBJECTv2.to_csv(export_root / \"SUBJECT.csv\", index=False)\n",
    "        CLINPATHv2.to_csv(export_root / \"CLINPATH.csv\", index=False)\n",
    "        DATAv2.to_csv(export_root / \"DATA.csv\", index=False)\n",
    "\n",
    "    return STUDYv2, PROTOCOLv2, SAMPLEv2, SUBJECTv2, CLINPATHv2, DATAv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load v1 tables \n",
    "tables_path = Path.home() / \"Projects/ASAP/crn-utils/resource/v1\"\n",
    "STUDYv1 = read_meta_table(f\"{tables_path}/STUDY.csv\")\n",
    "PROTOCOLv1 = read_meta_table(f\"{tables_path}/PROTOCOL.csv\")\n",
    "SUBJECTv1 = read_meta_table(f\"{tables_path}/SUBJECT.csv\")\n",
    "CLINPATHv1 = read_meta_table(f\"{tables_path}/CLINPATH.csv\")\n",
    "SAMPLEv1 = read_meta_table(f\"{tables_path}/SAMPLE.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDYv2, PROTOCOLv2, SAMPLEv2, SUBJECTv2, CLINPATHv2, DATAv2 = v1_to_v2(tables_path, None, CDEv1, CDEv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STUDYv2_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m STUDYv2\u001b[38;5;241m.\u001b[39mcolumns, \u001b[43mSTUDYv2_\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STUDYv2_' is not defined"
     ]
    }
   ],
   "source": [
    "STUDYv2.columns, STUDYv2_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STUDYv2_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mset\u001b[39m(STUDYv2\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mSTUDYv2_\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STUDYv2_' is not defined"
     ]
    }
   ],
   "source": [
    "set(STUDYv2.columns) - set(STUDYv2_.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load v2 tables for comparison with ouput of update_tables_to_CDEv2_\n",
    "tables_path = Path.home() / \"Projects/ASAP/crn-utils/resource/v2.1\"\n",
    "STUDYv2_ = read_meta_table(f\"{tables_path}/STUDY.csv\")\n",
    "PROTOCOLv2_ = read_meta_table(f\"{tables_path}/PROTOCOL.csv\")\n",
    "SUBJECTv2_ = read_meta_table(f\"{tables_path}/SUBJECT.csv\")\n",
    "CLINPATHv2_ = read_meta_table(f\"{tables_path}/CLINPATH.csv\")\n",
    "SAMPLEv2_ = read_meta_table(f\"{tables_path}/SAMPLE.csv\")\n",
    "DATAv2_ = read_meta_table(f\"{tables_path}/DATA.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes from v2.1 to v3.0\n",
    "\n",
    "### STUDY Table:\n",
    "- **New Fields:**\n",
    "  - `ASAP_team_name` (Required)\n",
    "  - `number_samples` (Required)\n",
    "  - `sample_types` (Required)\n",
    "  - `metadata_tables` (Required)\n",
    "  - `PI_ORCID` (Optional)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### SAMPLE Table:\n",
    "- **New Fields:**\n",
    "  - `condition_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` moved from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### SUBJECT Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### CLINPATH Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` moved from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - `AMPPD_id` changed from Required to Optional\n",
    "  - `GP2_id` changed from Required to Optional\n",
    "  - `ethnicity` changed from Required to Optional\n",
    "  - `family_history` changed from Required to Optional\n",
    "  - `last_diagnosis` changed from Required to Optional\n",
    "\n",
    "---\n",
    "\n",
    "### PMDBS Table (New Table):\n",
    "- **New Fields:**\n",
    "  - `sample_id` (Required)\n",
    "  - `brain_region` (Required)\n",
    "  - `hemisphere` (Optional)\n",
    "  - `region_level_1` (Required)\n",
    "  - `region_level_2` (Required)\n",
    "  - `region_level_3` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `sample_id` moved from `SAMPLE` and `DATA`\n",
    "  - `brain_region`, `hemisphere`, `region_level_1`, `region_level_2`, `region_level_3` moved from `SAMPLE`\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### CONDITION Table (New Table):\n",
    "- **New Fields:**\n",
    "  - `condition_id` (Required)\n",
    "  - `intervention_id` (Required)\n",
    "  - `protocol_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### MOUSE Table (New Table):\n",
    "- **New Fields:**\n",
    "  - `subject_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` moved from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### ASSAY_RNAseq Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `sample_id`, `tissue`, `RIN`, `molecular_source`, `input_cell_count`, `assay`, `sequencing_end`, `sequencing_length`, `sequencing_instrument` moved from `SAMPLE`\n",
    "  - `sample_id`, `technology`, `omic` moved from `DATA`\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### DATA Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and time\n",
    "current_date = datetime.datetime.now()\n",
    "    \n",
    "# STUDYv2 = read_meta_table(f\"{tables_path}/STUDY.csv\")\n",
    "# PROTOCOLv2 = read_meta_table(f\"{tables_path}/PROTOCOL.csv\")\n",
    "# SUBJECTv2 = read_meta_table(f\"{tables_path}/SUBJECT.csv\")\n",
    "# CLINPATHv2 = read_meta_table(f\"{tables_path}/CLINPATH.csv\")\n",
    "# SAMPLEv2 = read_meta_table(f\"{tables_path}/SAMPLE.csv\")\n",
    "# DATAv2 = read_meta_table(f\"{tables_path}/DATA.csv\")\n",
    "\n",
    "# STUDY\n",
    "STUDYv3 = STUDYv2.copy() # don't really need to copy here\n",
    "STUDYv3['metadata_tables'] = \"STUDY, PROTOCOL, SUBJECT, SAMPLE, DATA, CLINPATH, PMDBS, CONDITION, ASSAY_RNAseq\"\n",
    "# STUDYv3['number_samples'] = STUDYv2['number_of_brain_samples']\n",
    "# STUDYv3['sample_types'] = STUDYv2['brain_regions']\n",
    "STUDYv3.rename(columns={\"number_of_brain_samples\": \"number_samples\", \"brain_regions\": \"sample_types\"}, inplace=True)\n",
    "\n",
    "# PROTOCOL\n",
    "PROTOCOLv3 = PROTOCOLv1.copy()  \n",
    "\n",
    "# SUBJECT\n",
    "SUBJECTv3 = filter_table_columns(SUBJECTv2, CDEv3, \"SUBJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SAMPLE\n",
    "SAMPLEv3 = filter_table_columns(SAMPLEv2, CDEv3, \"SAMPLE\")\n",
    "\n",
    "# DATA\n",
    "DATAv3 = filter_table_columns(DATAv2, CDEv3, \"DATA\")\n",
    "DATAv3 = pd.merge(DATAv3, SAMPLEv3[['sample_id','time']], on=\"sample_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CLINPATH\n",
    "CLINPATHv3 = filter_table_columns(CLINPATHv2, CDEv3, \"CLINPATH\")\n",
    "# move these to CLINPATHv3 from SUBJECTv2\n",
    "cols_from_SUBJECTv2 = [\n",
    "    'AMPPD_id',\n",
    "    'GP2_id',\n",
    "    'ethnicity',\n",
    "    'family_history',\n",
    "    'last_diagnosis',\n",
    "    'age_at_onset',\n",
    "    'age_at_diagnosis',\n",
    "    'first_motor_symptom',\n",
    "    'hx_dementia_mci',\n",
    "    'hx_melanoma',\n",
    "    'education_level',\n",
    "    'smoking_status',\n",
    "    'smoking_years',\n",
    "    'APOE_e4_status',\n",
    "    'cognitive_status',\n",
    "    'time_from_baseline']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLINPATHv3_cols = [col for col in CLINPATHv3.columns if col not in cols_from_SUBJECTv2]\n",
    "cols_from_SUBJECTv2 += ['subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLINPATHv3_ = pd.merge(CLINPATHv3[CLINPATHv3_cols], SUBJECTv2[cols_from_SUBJECTv2], on=\"subject_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PMDBS\n",
    "PMDBSv3 = filter_table_columns(SAMPLEv2, CDEv3, \"PMDBS\")\n",
    "\n",
    "# ASSAY_RNAseq\n",
    "ASSAY_RNAseqv3 = filter_table_columns(SAMPLEv2, CDEv3, \"ASSAY_RNAseq\")\n",
    "\n",
    "ASSAY_RNAseqv3['technology'] = DATAv2['technology'][0]\n",
    "ASSAY_RNAseqv3['omic'] = DATAv2['omic'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONDITION\n",
    "# construct this table\n",
    "\n",
    "def intervention_typer(x):\n",
    "    if x is None:\n",
    "        return \"Control\"\n",
    "    else:\n",
    "        x = x.lower() \n",
    "        if x in [ NULL, \"\", \"Control\", \"Healthy\", \"HC\", \"No PD or other neurological disease\", \"No PD or other neurological disorder\"]:\n",
    "            return \"Control\"\n",
    "        elif x in [\"PD\", \"Parkinson's Disease\"]:\n",
    "            return \"Case\"\n",
    "        elif x == \"Other neurological disorder\":\n",
    "            return \"Other Control\"\n",
    "        else:\n",
    "            return \"Case\"\n",
    "\n",
    "CONDITIONv3 = pd.DataFrame(columns=CDEv3[CDEv3['Table'] == \"CONDITION\"]['Field'])\n",
    "CONDITIONv3['condition_id'] = SUBJECTv3['primary_diagnosis'].unique()\n",
    "CONDITIONv3['intervention_name'] = \"Case-Control\"\n",
    "CONDITIONv3['intervention_type'] = CONDITIONv3['condition_id'].apply(intervention_typer)\n",
    "\n",
    "# SAMPLEv3['condition_id'] = SAMPLEv3['sample_id'].map(SUBJECTv3.set_index('subject_id')['primary_diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update function for CDEv3 (transforming from v2.1 to v3)\n",
    "def intervention_typer(x):\n",
    "    if x is None:\n",
    "        return \"Control\"\n",
    "    else:\n",
    "        x = x.lower() \n",
    "        if x in [ NULL, \"\", \"Control\", \"Healthy\", \"HC\", \"No PD or other neurological disease\", \"No PD or other neurological disorder\"]:\n",
    "            return \"Control\"\n",
    "        elif x in [\"PD\", \"Parkinson's Disease\"]:\n",
    "            return \"Case\"\n",
    "        elif x == \"Other neurological disorder\":\n",
    "            return \"Other Control\"\n",
    "        else:\n",
    "            return \"Case\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def v2_to_v3_PMDBS(tables_path: str | Path, out_dir: str, CDEv2: pd.DataFrame, CDEv3: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Load the tables from the tables_path, and update them to the CDEv3 schema.\n",
    "    Export the new tables to a datestamped out_dir.\n",
    "    \"\"\"\n",
    "    current_date = datetime.datetime.now()\n",
    "\n",
    "    # Load the tables\n",
    "    STUDYv2 = read_meta_table(f\"{tables_path}/STUDY.csv\")\n",
    "    PROTOCOLv2 = read_meta_table(f\"{tables_path}/PROTOCOL.csv\")\n",
    "    SUBJECTv2 = read_meta_table(f\"{tables_path}/SUBJECT.csv\")\n",
    "    CLINPATHv2 = read_meta_table(f\"{tables_path}/CLINPATH.csv\")\n",
    "    SAMPLEv2 = read_meta_table(f\"{tables_path}/SAMPLE.csv\")\n",
    "    DATAv2 = read_meta_table(f\"{tables_path}/DATA.csv\")\n",
    "\n",
    "    # STUDY\n",
    "    STUDYv3 = STUDYv2.copy() # don't really need to copy here\n",
    "    STUDYv3['metadata_tables'] = \"STUDY, PROTOCOL, SUBJECT, SAMPLE, DATA, CLINPATH, PMDBS, CONDITION, ASSAY_RNAseq\"\n",
    "    # STUDYv3['number_samples'] = STUDYv2['number_of_brain_samples']\n",
    "    # STUDYv3['sample_types'] = STUDYv2['brain_regions']\n",
    "    STUDYv3.rename(columns={\"number_of_brain_samples\": \"number_samples\", \"brain_regions\": \"sample_types\"}, inplace=True)\n",
    "\n",
    "    STUDYv3 = filter_table_columns(STUDYv2, CDEv3, \"STUDY\")\n",
    "    \n",
    "    # PROTOCOL\n",
    "    PROTOCOLv3 = PROTOCOLv1.copy()  \n",
    "\n",
    "    # SUBJECT\n",
    "    SUBJECTv3 = filter_table_columns(SUBJECTv2, CDEv3, \"SUBJECT\")\n",
    "\n",
    "    # PMDBS\n",
    "    PMDBSv3 = filter_table_columns(SAMPLEv2, CDEv3, \"PMDBS\")\n",
    "    # ASSAY_RNAseq\n",
    "    ASSAY_RNAseqv3 = filter_table_columns(SAMPLEv2, CDEv3, \"ASSAY_RNAseq\")\n",
    "    ASSAY_RNAseqv3['technology'] = DATAv2['technology'][0]\n",
    "    ASSAY_RNAseqv3['omic'] = DATAv2['omic'][0]\n",
    "\n",
    "    # CLINPATH\n",
    "    CLINPATHv3 = filter_table_columns(CLINPATHv2, CDEv3, \"CLINPATH\")\n",
    "    # move these to CLINPATHv3 from SUBJECTv2\n",
    "    cols_from_SUBJECTv2 = [\n",
    "        'AMPPD_id',\n",
    "        'GP2_id',\n",
    "        'ethnicity',\n",
    "        'family_history',\n",
    "        'last_diagnosis',\n",
    "        'age_at_onset',\n",
    "        'age_at_diagnosis',\n",
    "        'first_motor_symptom',\n",
    "        'hx_dementia_mci',\n",
    "        'hx_melanoma',\n",
    "        'education_level',\n",
    "        'smoking_status',\n",
    "        'smoking_years',\n",
    "        'APOE_e4_status',\n",
    "        'cognitive_status',\n",
    "        'time_from_baseline']\n",
    "    CLINPATHv3_cols = [col for col in CLINPATHv3.columns if col not in cols_from_SUBJECTv2]\n",
    "    cols_from_SUBJECTv2 += ['subject_id']\n",
    "    CLINPATHv3_ = pd.merge(CLINPATHv3[CLINPATHv3_cols], SUBJECTv2[cols_from_SUBJECTv2], on=\"subject_id\", how=\"left\")\n",
    "\n",
    "    # PMDBS\n",
    "    PMDBSv3 = filter_table_columns(SAMPLEv2, CDEv3, \"PMDBS\")\n",
    "    # ASSAY_RNAseq\n",
    "    ASSAY_RNAseqv3 = filter_table_columns(SAMPLEv2, CDEv3, \"ASSAY_RNAseq\")\n",
    "    ASSAY_RNAseqv3['technology'] = DATAv2['technology'][0]\n",
    "    ASSAY_RNAseqv3['omic'] = DATAv2['omic'][0]\n",
    "\n",
    "\n",
    "    # DATA\n",
    "    DATAv3 = filter_table_columns(DATAv2, CDEv3, \"DATA\")\n",
    "    DATAv3 = pd.merge(DATAv3, SAMPLEv3[['sample_id','time']], on=\"sample_id\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "    # CONDITION\n",
    "    # construct this table.  needs to be checked by hand\n",
    "    CONDITIONv3 = pd.DataFrame(columns=CDEv3[CDEv3['Table'] == \"CONDITION\"]['Field'])\n",
    "    CONDITIONv3['condition_id'] = SUBJECTv3['primary_diagnosis'].unique()\n",
    "    CONDITIONv3['intervention_name'] = \"Case-Control\"\n",
    "    CONDITIONv3['intervention_type'] = CONDITIONv3['condition_id'].apply(intervention_typer)\n",
    "    if out_dir is not None:\n",
    "\n",
    "        # Prepare output directory\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        export_root = Path(tables_path) / f\"{out_dir}_{date_str}\"\n",
    "        export_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Export the tables\n",
    "        STUDYv3.to_csv(export_root / \"STUDY.csv\", index=False)\n",
    "        PROTOCOLv3.to_csv(export_root / \"PROTOCOL.csv\", index=False)\n",
    "        SAMPLEv3.to_csv(export_root / \"SAMPLE.csv\", index=False)\n",
    "        SUBJECTv3.to_csv(export_root / \"SUBJECT.csv\", index=False)\n",
    "        CLINPATHv3.to_csv(export_root / \"CLINPATH.csv\", index=False)\n",
    "        DATAv3.to_csv(export_root / \"DATA.csv\", index=False)\n",
    "        PMDBSv3.to_csv(export_root / \"PMDBS.csv\", index=False)\n",
    "        CONDITIONv3.to_csv(export_root / \"CONDITION.csv\", index=False)\n",
    "        ASSAY_RNAseqv3.to_csv(export_root / \"ASSAY_RNAseq.csv\", index=False)\n",
    "\n",
    "    return STUDYv3, PROTOCOLv3, SAMPLEv3, SUBJECTv3, DATAv3, CLINPATHv3, ASSAY_RNAseqv3, PMDBSv3, CONDITIONv3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = v2_to_v3_PMDBS(tables_path, None, CDEv2, CDEv3)\n",
    "\n",
    "STUDYv3, PROTOCOLv3, SAMPLEv3, SUBJECTv3, DATAv3, CLINPATHv3, ASSAY_RNAseqv3, PMDBSv3, CONDITIONv3 = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit NOT successfully imported\n"
     ]
    }
   ],
   "source": [
    "from validate import validate_table, ReportCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recoding number_samples as int\n",
      "All required fields are present in *STUDY* table.\n",
      "ðŸš¨âš ï¸â— **4 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- other_funding_source: 1/1 empty rows (REQUIRED)\n",
      "\n",
      "\t- publication_DOI: 1/1 empty rows (REQUIRED)\n",
      "\n",
      "\t- publication_PMID: 1/1 empty rows (REQUIRED)\n",
      "\n",
      "\t- PI_google_scholar_id: 1/1 empty rows (OPTIONAL)\n",
      "ðŸš¨âš ï¸â— **1 Fields with invalid entries:**\n",
      "- _*number_samples*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ int or NULL ('NA')\n",
      "\n",
      "All required fields are present in *PROTOCOL* table.\n",
      "ðŸš¨âš ï¸â— **1 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- other_reference: 1/1 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "All required fields are present in *SUBJECT* table.\n",
      "ðŸš¨âš ï¸â— **1 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- primary_diagnosis_text: 23/25 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "recoding age_at_onset as int\n",
      "recoding age_at_diagnosis as int\n",
      "recoding first_motor_symptom as int\n",
      "All required fields are present in *CLINPATH* table.\n",
      "ðŸš¨âš ï¸â— **27 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- path_autopsy_second_dx: 17/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_third_dx: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_fourth_dx: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_fifth_dx: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_sixth_dx: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_seventh_dx: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_autopsy_eight_dx: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_year_death: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- cause_death: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- other_cause_death_1: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- other_cause_death_2: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- brain_weight: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_braak_asyn: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_cerad: 18/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_thal: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- known_pathogenic_mutation: 24/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- PD_pathogenic_mutation: 24/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- sn_neuronal_loss: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_infarcs: 22/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_a: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_b: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- path_nia_aa_c: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- TDP43: 12/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- arteriolosclerosis_severity_scale: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- amyloid_angiopathy_severity_scale: 23/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- dig_slide_avail: 25/25 empty rows (OPTIONAL)\n",
      "\n",
      "\t- quant_path_avail: 25/25 empty rows (OPTIONAL)\n",
      "ðŸš¨âš ï¸â— **27 Fields with invalid entries:**\n",
      "- _*family_history*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'Yes', 'No', 'Unknown', 'Not Reported'\n",
      "- _*age_at_onset*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ int or NULL ('NA')\n",
      "- _*age_at_diagnosis*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ int or NULL ('NA')\n",
      "- _*first_motor_symptom*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ int or NULL ('NA')\n",
      "- _*hx_dementia_mci*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'Yes', 'No'\n",
      "- _*hx_melanoma*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'Yes', 'No'\n",
      "- _*education_level*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'High School', 'High School/GED', 'Some college without degree', 'Associate degree college', 'Bachelor's degree', 'Master's degree', 'Professional or doctoral degree', 'Refuse', 'Other'\n",
      "- _*smoking_status*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'Current smoker', 'Former smoker', 'Never', 'Unknown'\n",
      "- _*smoking_years*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ float or NULL ('NA')\n",
      "- _*APOE_e4_status*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ '22', '23', '24', '33', '34', '44', 'Unknown'\n",
      "- _*cognitive_status*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'Normal', 'MCI', 'Dementia'\n",
      "- _*path_braak_asyn*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ '0', '1', '2', '3', '4', '5', '6', '1/2', '3/4', '4/5', '5/6'\n",
      "- _*path_cerad*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'None', 'Sparse', 'Moderate', 'Frequent'\n",
      "- _*path_thal*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ '0', '1', '2', '3', '4', '5', '1/2', '3', '4/5'\n",
      "- _*known_pathogenic_mutation*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'None', 'Present', 'Unknown'\n",
      "- _*sn_neuronal_loss*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'None', 'Mild', 'Moderate', 'Severe', 'Not assessed', 'Unknown'\n",
      "- _*path_infarcs*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'Yes', 'No'\n",
      "- _*path_nia_ri*_:  invalid values ðŸ’©'Criteria not met', 'Not AD'\n",
      "    - valid âž¡ï¸ 'Low', 'Intermediate', 'High', 'None'\n",
      "- _*path_nia_aa_a*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'A0', 'A1', 'A2', 'A3'\n",
      "- _*path_nia_aa_b*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'B0', 'B1', 'B2', 'B3'\n",
      "- _*path_nia_aa_c*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'C0', 'C1', 'C2', 'C3'\n",
      "- _*TDP43*_:  invalid values ðŸ’©'NA', 'Na'\n",
      "    - valid âž¡ï¸ 'None in medial temporal lobe', 'Present in amygdala, only', 'Present in hippocampus, only', 'Present in amygdala and hippocampus, only', 'Present in medial temporal lobe and middle frontal gyrus (not FTLD pattern)', 'Unknown'\n",
      "- _*arteriolosclerosis_severity_scale*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'None', 'Mild', 'Moderate', 'Severe', 'Not assessed', 'Unknown'\n",
      "- _*amyloid_angiopathy_severity_scale*_:  invalid values ðŸ’©'NA', 'Cerebral amyloid angiopathy, temporal and occipital lobe', 'Cerebral amyloid angiopathy, frontal lobe'\n",
      "    - valid âž¡ï¸ 'None', 'Mild', 'Moderate', 'Severe', 'Not assessed', 'Unknown'\n",
      "- _*path_ad_level*_:  invalid values ðŸ’©'Microscopic changes of Alzheimer's disease, insufficient for diagnosis', 'Microscopic lesions of Alzheimer's disease, insufficient for diagnosis'\n",
      "    - valid âž¡ï¸ 'No evidence of Alzheimer's disease neuropathological change', 'Low level Alzheimer's disease neuropathological change', 'At least low level Alzheimer's disease neuropathological change', 'Intermediate level Alzheimer's disease neuropathological change', 'At least intermediate level Alzheimer's disease neuropathological change', 'High level Alzheimer's disease neuropathological change', 'Unknown'\n",
      "- _*dig_slide_avail*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'Yes', 'No'\n",
      "- _*quant_path_avail*_:  invalid values ðŸ’©'NA'\n",
      "    - valid âž¡ï¸ 'Yes', 'No'\n",
      "\n",
      "recoding replicate_count as int\n",
      "recoding repeated_sample as int\n",
      "All required fields are present in *SAMPLE* table.\n",
      "ðŸš¨âš ï¸â— **5 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- self_reported_ethnicity_ontology_term_id: 75/75 empty rows (OPTIONAL)\n",
      "\n",
      "\t- donor_id: 75/75 empty rows (OPTIONAL)\n",
      "\n",
      "\t- pm_PH: 75/75 empty rows (OPTIONAL)\n",
      "\n",
      "\t- source_RIN: 75/75 empty rows (OPTIONAL)\n",
      "\n",
      "\t- DV200: 75/75 empty rows (OPTIONAL)\n",
      "ðŸš¨âš ï¸â— **3 Fields with invalid entries:**\n",
      "- _*organism*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'Human', 'Mouse', 'Dog', 'Fly', 'Other'\n",
      "- _*assay_type*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ 'scRNAseq', 'snRNAseq', 'bulkRNAseq'\n",
      "- _*time*_:  invalid values ðŸ’©'None'\n",
      "    - valid âž¡ï¸ float or NULL ('NA')\n",
      "\n",
      "recoding replicate_count as int\n",
      "recoding repeated_sample as int\n",
      "All required fields are present in *DATA* table.\n",
      "ðŸš¨âš ï¸â— **2 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- header: 150/150 empty rows (OPTIONAL)\n",
      "\n",
      "\t- annotation: 150/150 empty rows (OPTIONAL)\n",
      "No invalid entries found in Enum fields.\n",
      "ðŸš¨âš ï¸â— **Extra field in DATA: time**\n",
      "\n",
      "All required fields are present in *PMDBS* table.\n",
      "No empty entries (NULL) found .\n",
      "No invalid entries found in Enum fields.\n",
      "\n",
      "All required fields are present in *CONDITION* table.\n",
      "No empty entries (NULL) found .\n",
      "No invalid entries found in Enum fields.\n",
      "ðŸš¨âš ï¸â— **Extra field in CONDITION: intervention_type**\n",
      "\n",
      "recoding input_cell_count as int\n",
      "recoding sequencing_length as int\n",
      "All required fields are present in *ASSAY_RNAseq* table.\n",
      "ðŸš¨âš ï¸â— **1 Fields with empty (NULL) values:**\n",
      "\n",
      "\t- RIN: 75/75 empty rows (REQUIRED)\n",
      "No invalid entries found in Enum fields.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_dfs = [STUDYv3, PROTOCOLv3, SUBJECTv3, CLINPATHv3, SAMPLEv3, DATAv3, PMDBSv3, CONDITIONv3, ASSAY_RNAseqv3]\n",
    "tables = ['STUDY', 'PROTOCOL', 'SUBJECT', 'CLINPATH', 'SAMPLE', 'DATA', 'PMDBS', 'CONDITION', 'ASSAY_RNAseq']\n",
    "for table,df in zip(tables,table_dfs):\n",
    "\n",
    "    schema = CDEv3[CDEv3['Table'] == table]\n",
    "\n",
    "    report = ReportCollector(destination=\"NA\")\n",
    "    full_table_, report = validate_table(df.copy(), table, schema, report)\n",
    "    report.print_log()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_schema_changes(old_schema: pd.DataFrame, new_schema: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Summarizes the changes made between two schema versions.\n",
    "    \n",
    "    Parameters:\n",
    "    - old_schema (pd.DataFrame): The old schema DataFrame.\n",
    "    - new_schema (pd.DataFrame): The new schema DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A summary of the changes.\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "\n",
    "    # Group schemas by tables\n",
    "    old_schema_grouped = old_schema.groupby('Table')\n",
    "    new_schema_grouped = new_schema.groupby('Table')\n",
    "\n",
    "    all_tables = set(old_schema['Table'].unique()).union(set(new_schema['Table'].unique()))\n",
    "\n",
    "    for table in all_tables:\n",
    "        old_table_schema = old_schema_grouped.get_group(table) if table in old_schema_grouped.groups else pd.DataFrame()\n",
    "        new_table_schema = new_schema_grouped.get_group(table) if table in new_schema_grouped.groups else pd.DataFrame()\n",
    "\n",
    "        # Extract fields and required status from each version\n",
    "        old_fields = set(old_table_schema['Field'].tolist())\n",
    "        new_fields = set(new_table_schema['Field'].tolist())\n",
    "\n",
    "        old_required = old_table_schema[old_table_schema['Required'] == 'Required']['Field'].tolist()\n",
    "        new_required = new_table_schema[new_table_schema['Required'] == 'Required']['Field'].tolist()\n",
    "\n",
    "        # Summarize the changes for each table\n",
    "        moved_fields = {\n",
    "            field for field in old_fields.intersection(new_fields)\n",
    "            if old_table_schema[old_table_schema['Field'] == field]['Table'].iloc[0]\n",
    "            != new_table_schema[new_table_schema['Field'] == field]['Table'].iloc[0]\n",
    "        }\n",
    "\n",
    "        summary[table] = {\n",
    "            'added_fields': new_fields - old_fields,\n",
    "            'deleted_fields': old_fields - new_fields,\n",
    "            'moved_fields': moved_fields,\n",
    "            'fields_now_required': set(new_required) - set(old_required),\n",
    "            'fields_now_optional': set(old_required) - set(new_required)\n",
    "        }\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_paht = Path.home() / \"Projects/ASAP/crn-meta-validate\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load schemas as DataFrames (ensure proper file paths)\n",
    "old_schema_v1 = pd.read_csv('path_to_v1_schema.csv')\n",
    "new_schema_v2_1 = pd.read_csv('path_to_v2_1_schema.csv')\n",
    "new_schema_v3 = pd.read_csv('path_to_v3_schema.csv')\n",
    "\n",
    "# Run the schema comparison\n",
    "schema_changes_v1_to_v2_1 = summarize_schema_changes(old_schema_v1, new_schema_v2_1)\n",
    "schema_changes_v2_1_to_v3 = summarize_schema_changes(new_schema_v2_1, new_schema_v3)\n",
    "\n",
    "# Format the changes into bullet lists\n",
    "formatted_changes_v1_to_v2_1 = format_schema_changes(schema_changes_v1_to_v2_1)\n",
    "formatted_changes_v2_1_to_v3 = format_schema_changes(schema_changes_v2_1_to_v3)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nChanges from v1 to v2.1:\")\n",
    "for change in formatted_changes_v1_to_v2_1:\n",
    "    print(change)\n",
    "\n",
    "print(\"\\nChanges from v2.1 to v3:\")\n",
    "for change in formatted_changes_v2_1_to_v3:\n",
    "    print(change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assume that 'old_schema_v1' and 'new_schema_v2_1' are already loaded as DataFrames\n",
    "schema_changes_v1_to_v2_1 = summarize_schema_changes(old_schema_v1, new_schema_v2_1)\n",
    "schema_changes_v2_1_to_v3 = summarize_schema_changes(new_schema_v2_1, new_schema_v3)\n",
    "\n",
    "# Output the summarized changes for v1 to v2.1 and v2.1 to v3\n",
    "print(\"Changes from v1 to v2.1:\")\n",
    "print(schema_changes_v1_to_v2_1)\n",
    "\n",
    "print(\"\\nChanges from v2.1 to v3:\")\n",
    "print(schema_changes_v2_1_to_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_schema_changes(old_schema: pd.DataFrame, new_schema: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Summarizes the changes made between two schema versions.\n",
    "    \n",
    "    Parameters:\n",
    "    - old_schema (pd.DataFrame): The old schema DataFrame.\n",
    "    - new_schema (pd.DataFrame): The new schema DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A summary of the changes.\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "\n",
    "    # Group schemas by tables\n",
    "    old_schema_grouped = old_schema.groupby('Table')\n",
    "    new_schema_grouped = new_schema.groupby('Table')\n",
    "\n",
    "    all_tables = set(old_schema['Table'].unique()).union(set(new_schema['Table'].unique()))\n",
    "\n",
    "    for table in all_tables:\n",
    "        old_table_schema = old_schema_grouped.get_group(table) if table in old_schema_grouped.groups else pd.DataFrame()\n",
    "        new_table_schema = new_schema_grouped.get_group(table) if table in new_schema_grouped.groups else pd.DataFrame()\n",
    "\n",
    "        # Extract fields and required status from each version\n",
    "        old_fields = set(old_table_schema['Field'].tolist())\n",
    "        new_fields = set(new_table_schema['Field'].tolist())\n",
    "\n",
    "        old_required = old_table_schema[old_table_schema['Required'] == 'Required']['Field'].tolist()\n",
    "        new_required = new_table_schema[new_table_schema['Required'] == 'Required']['Field'].tolist()\n",
    "\n",
    "        # Summarize the changes for each table\n",
    "        moved_fields = {\n",
    "            field for field in old_fields.intersection(new_fields)\n",
    "            if old_table_schema[old_table_schema['Field'] == field]['Table'].iloc[0]\n",
    "            != new_table_schema[new_table_schema['Field'] == field]['Table'].iloc[0]\n",
    "        }\n",
    "\n",
    "        summary[table] = {\n",
    "            'added_fields': new_fields - old_fields,\n",
    "            'deleted_fields': old_fields - new_fields,\n",
    "            'moved_fields': moved_fields,\n",
    "            'fields_now_required': set(new_required) - set(old_required),\n",
    "            'fields_now_optional': set(old_required) - set(new_required)\n",
    "        }\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Assume that 'old_schema_v1' and 'new_schema_v2_1' are already loaded as DataFrames\n",
    "    schema_changes_v1_to_v2_1 = summarize_schema_changes(old_schema_v1, new_schema_v2_1)\n",
    "    schema_changes_v2_1_to_v3 = summarize_schema_changes(new_schema_v2_1, new_schema_v3)\n",
    "\n",
    "    # Output the summarized changes for v1 to v2.1 and v2.1 to v3\n",
    "    print(\"Changes from v1 to v2.1:\")\n",
    "    print(schema_changes_v1_to_v2_1)\n",
    "\n",
    "    print(\"\\nChanges from v2.1 to v3:\")\n",
    "    print(schema_changes_v2_1_to_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables in v1:\n",
    "- STUDY\n",
    "- PROTOCOL\n",
    "- SUBJECT\n",
    "- SAMPLE\n",
    "- CLINPATH\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Tables in v2.1:\n",
    "- STUDY\n",
    "- PROTOCOL\n",
    "- SUBJECT\n",
    "- SAMPLE\n",
    "- CLINPATH\n",
    "- ASSAY_RNAseq\n",
    "- DATA\n",
    "\n",
    "---\n",
    "\n",
    "## Tables in v3.0:\n",
    "- STUDY\n",
    "- PROTOCOL\n",
    "- SUBJECT\n",
    "- SAMPLE\n",
    "- CLINPATH\n",
    "- ASSAY_RNAseq (+ Other)\n",
    "- DATA\n",
    "- PMDBS\n",
    "- CONDITION\n",
    "- MOUSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes from v1 to v2.1\n",
    "\n",
    "### STUDY Table:\n",
    "- **New Fields:**\n",
    "  - `team_dataset_id` (Required)\n",
    "  - `alternate_dataset_id` (Optional)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### SAMPLE Table:\n",
    "- **New Fields:**\n",
    "  - `alternate_sample_id` (Optional)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `brain_region` moved from `SAMPLE` (Required)\n",
    "  - `hemisphere` moved from `SAMPLE` (Required)\n",
    "  - `region_level_1` moved from `SAMPLE` (Required)\n",
    "  - `region_level_2` moved from `SAMPLE` (Required)\n",
    "  - `region_level_3` moved from `SAMPLE` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### SUBJECT Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### CLINPATH Table:\n",
    "- **New Fields:**\n",
    "  - `subject_id` (Required)\n",
    "  - `source_subject_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` added from `SUBJECT` (Required)\n",
    "  - `source_subject_id` added from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### DATA Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `sample_id` moved from `SAMPLE` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes from v2.1 to v3.0\n",
    "\n",
    "### STUDY Table:\n",
    "- **New Fields:**\n",
    "  - `ASAP_team_name` (Required)\n",
    "  - `number_samples` (Required)\n",
    "  - `sample_types` (Required)\n",
    "  - `metadata_tables` (Required)\n",
    "  - `PI_ORCID` (Optional)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### SAMPLE Table:\n",
    "- **New Fields:**\n",
    "  - `condition_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` moved from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### SUBJECT Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### CLINPATH Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` moved from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - `AMPPD_id` changed from Required to Optional\n",
    "  - `GP2_id` changed from Required to Optional\n",
    "  - `ethnicity` changed from Required to Optional\n",
    "  - `family_history` changed from Required to Optional\n",
    "  - `last_diagnosis` changed from Required to Optional\n",
    "\n",
    "---\n",
    "\n",
    "### PMDBS Table (New Table):\n",
    "- **New Fields:**\n",
    "  - `sample_id` (Required)\n",
    "  - `brain_region` (Required)\n",
    "  - `hemisphere` (Optional)\n",
    "  - `region_level_1` (Required)\n",
    "  - `region_level_2` (Required)\n",
    "  - `region_level_3` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `sample_id` moved from `SAMPLE` and `DATA`\n",
    "  - `brain_region`, `hemisphere`, `region_level_1`, `region_level_2`, `region_level_3` moved from `SAMPLE`\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### CONDITION Table (New Table):\n",
    "- **New Fields:**\n",
    "  - `condition_id` (Required)\n",
    "  - `intervention_id` (Required)\n",
    "  - `protocol_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### MOUSE Table (New Table):\n",
    "- **New Fields:**\n",
    "  - `subject_id` (Required)\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `subject_id` moved from `SUBJECT` (Required)\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### ASSAY_RNAseq Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - `sample_id`, `tissue`, `RIN`, `molecular_source`, `input_cell_count`, `assay`, `sequencing_end`, `sequencing_length`, `sequencing_instrument` moved from `SAMPLE`\n",
    "  - `sample_id`, `technology`, `omic` moved from `DATA`\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n",
    "\n",
    "---\n",
    "\n",
    "### DATA Table:\n",
    "- **New Fields:**\n",
    "  - None\n",
    "\n",
    "- **Fields Moved from Another Table:**\n",
    "  - None\n",
    "\n",
    "- **Fields Changed from Required to Optional:**\n",
    "  - None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v1: *id Fields by Table\n",
    "\n",
    "### CLINPATH Table:\n",
    "- `sample_id`\n",
    "- `source_sample_id`\n",
    "- `GP2_id`\n",
    "- `AMPPD_id`\n",
    "\n",
    "### SAMPLE Table:\n",
    "- `source_sample_id`\n",
    "- `subject_id`\n",
    "- `organism_ontology_id`\n",
    "\n",
    "### STUDY Table:\n",
    "- `ASAP_grant_id`\n",
    "- `PI_google_scholar_id`\n",
    "\n",
    "### SUBJECT Table:\n",
    "- `subject_id`\n",
    "- `source_subject_id`\n",
    "\n",
    "---\n",
    "\n",
    "## v2.1: *id Fields by Table\n",
    "\n",
    "### CLINPATH Table:\n",
    "- `subject_id`\n",
    "- `source_subject_id`\n",
    "\n",
    "### DATA Table:\n",
    "- `sample_id`\n",
    "\n",
    "### SAMPLE Table:\n",
    "- `sample_id`\n",
    "- `subject_id`\n",
    "- `source_sample_id`\n",
    "- `organism_ontology_id`\n",
    "\n",
    "### STUDY Table:\n",
    "- `team_dataset_id`\n",
    "- `ASAP_grant_id`\n",
    "- `PI_google_scholar_id`\n",
    "- `alternate_dataset_id`\n",
    "\n",
    "### SUBJECT Table:\n",
    "- `subject_id`\n",
    "- `source_subject_id`\n",
    "- `AMPPD_id`\n",
    "- `GP2_id`\n",
    "\n",
    "---\n",
    "\n",
    "## v3.0: *id Fields by Table\n",
    "\n",
    "### ASSAY_RNAseq Table:\n",
    "- `sample_id`\n",
    "\n",
    "### CLINPATH Table:\n",
    "- `subject_id`\n",
    "- `source_subject_id`\n",
    "- `AMPPD_id`\n",
    "- `GP2_id`\n",
    "\n",
    "### CONDITION Table:\n",
    "- `condition_id`\n",
    "- `intervention_id`\n",
    "- `protocol_id`\n",
    "\n",
    "### DATA Table:\n",
    "- `sample_id`\n",
    "\n",
    "### MOUSE Table:\n",
    "- `subject_id`\n",
    "\n",
    "### PMDBS Table:\n",
    "- `sample_id`\n",
    "\n",
    "### SAMPLE Table:\n",
    "- `sample_id`\n",
    "- `subject_id`\n",
    "- `source_sample_id`\n",
    "- `condition_id`\n",
    "\n",
    "### STUDY Table:\n",
    "- `team_dataset_id`\n",
    "- `ASAP_grant_id`\n",
    "- `PI_google_scholar_id`\n",
    "- `alternate_dataset_id`\n",
    "\n",
    "### SUBJECT Table:\n",
    "- `subject_id`\n",
    "- `source_subject_id`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
